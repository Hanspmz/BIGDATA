{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Data-Intensive Applications chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are some advantages of binary encodings based on schemas?\n",
    "- They are much more compact than the various “binary JSON” variants because they can omit field names from the encoded data.\n",
    "- The schema is a valuable form of documentation and also because the schema is required for decoding\n",
    "- Keeping a database of schemas allows you to check forward and backward compatibility of schema changes, before anything is deployed.\n",
    "- For some users the ability to generate code from the schema is useful, since it enables type checking at compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are 3 popular standardized encodings:\n",
    "- JSON, XML, and CSV are textual formats, and thus somewhat human-readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are some problems of Standardized encoding?\n",
    "- There is a lot of ambiguity around the encoding of numbers. In XML and CSV, you cannot distinguish between a number and a string that happens to consist of digits.\n",
    "- JSON distinguishes strings and numbers, but it doesn’t distinguish integers and floating-point numbers, and it doesn’t specify a precision.\n",
    "- CSV does not have any schema, so it is up to the application to define the meaning of each row and column. If an application change adds a new row or column, you have to handle that change manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Data Flow?\n",
    "- it is how the data flows through your system and it consider data usage patterns, application boundaries, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name the dataflows mentioned in the book?\n",
    "- Dataflow through Databases\n",
    "- Dataflow through Services: REST and RPC\n",
    "- Message-Passing Dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Dataflow through Databases\n",
    "- An approach that deals data principally through databases is using what is known as an integration database. Heavy-on-database data flow is an architectural pattern commonly associated with monolithic architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is REST and RPC\n",
    "- REST emphasizes simple data formats, using URLs for identifying resources and using HTTP features for cache control, authentication, and content type negotiation.\n",
    "- The RPC (Remote Procedure Call) model tries to make a request to a remote network service look the same as calling a function or method in your programming language, within the same process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
